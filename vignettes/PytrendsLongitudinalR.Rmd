---
title: "PytrendsLongitudinalR"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{PytrendsLongitudinalR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


Welcome to the vignette for PytrendsLongitudinalR, a package for collecting and analyzing Google Trends data over time. This vignette will guide you through the setup process and show you how to use the package's main functionalities.

This is a package for downloading cross-section and time-series Google Trends and converting them to longitudinal data.
Although Google Trends provides cross-section and time-series search data, longitudinal Google Trends data are not readily available. There exist several practical issues that make it difficult for researchers to generate longitudinal Google Trends data themselves. First, Google Trends provides normalized counts from zero to 100. As a result, combining different regions' time-series Google Trends data does not create desired longitudinal data. For the same reason, combining cross-sectional Google Trends data over time does not create desired longitudinal data. Second, Google Trends has restrictions on data formats and timeline. For instance, if you want to collect daily data for 2 years, you cannot do so. Google Trends automatically provides weekly data if your request timeline is more than 269 days. Similarly, Google Trends automatically provides monthly data if your request timeline is more than 269 weeks even though you want to collect weekly data.
This package resolves the aforementioned issues and allows researchers to generate longitudinal Google Trends.


## Usage

Now you can start using PytrendsLongitudinalR to collect Google Trends data.
```{r usage, eval = FALSE}
library(PytrendsLongitudinalR)

# Initialize parameters for data collection
params <- initialize_request_trends(
  keyword = "Joe Biden",
  topic = "/m/012gx2",
  folder_name = "biden_save",
  start_date = "2024-05-01",
  end_date = "2024-05-03",
  data_format = "daily"
)

# Collect cross-section data
cross_section(params, geo = "US", resolution = "REGION")

# Collect time series data
time_series(params, reference_geo_code = "US-CA")

convert_cross_section(params, reference_geo_code = "US-CA")
```

## WARNING
Please make sure to run the methods in the following sequence:

cross_section

time_series

concat_time_series

convert_time_series

We have noticed some unusual behaviors if not run in the given sequence. Firstly concat_time_series depends on time_series and convert_cross_section depends on all the three. We have noticed if time_series is ran before cross_section then sometimes the output gets influenced by time_series parameters. We are troubleshooting the issue. Until then, please follow the sequence to attain the expected result.


When using the initialize_request_trends, cross_section, time_series, and convert_cross_section functions, you might encounter a 429 Too Many Requests error. This error indicates that you have exceeded the rate limits set by the Google Trends API. 
Here are a few strategies to mitigate the impact of this error:

1) Lower the frequency of your requests or extend the time periods between requests. If you're making requests with high frequency, consider spacing them out or reducing the number of requests made in a given time frame.

2) Adjust Time Periods: If you're querying a large time range or a high-resolution granularity, try reducing the scope of your queries. Smaller time periods or lower resolution might help stay within the rate limits.
