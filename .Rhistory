create_required_directory(file.path(folder_name, data_format, "by_region"))
if (data_format == 'daily') {
chng_delta <- lubridate::days(1)
end_delta <- lubridate::days(0)
form <- 'day'
} else if (data_format == 'weekly') {
chng_delta <- lubridate::weeks(1)
end_delta <- lubridate::weeks(1) - lubridate::days(1)
form <- 'week'
} else if (data_format == 'monthly') {
chng_delta <- lubridate::months(1)
end_delta <- lubridate::months(1) - lubridate::days(1)
form <- 'month'
}
current_time <- start_date
i <- 0
logger$info("Please note that this method may take hours to finish. Have patience.", extra = list(markup = TRUE))
while (TRUE) {
if ((data_format == 'weekly' && current_time >= end_date) || (data_format != 'weekly' && current_time > end_date)) {
break
}
current_end_time <- current_time + end_delta
current_time_str <- format(current_time, "%Y-%m-%d")
current_end_time_str <- format(current_end_time, "%Y-%m-%d")
cat(current_time_str,"\n")
cat(current_end_time_str,"\n")
file_path <- file.path(folder_name, data_format, "by_region", sprintf("%s_%d-%s-%s.csv", form, i + 1, current_time_str, current_end_time_str))
if (file.exists(file_path)) {
logger$info(sprintf("Data for %s-%s already collected. Moving to next date...", current_time_str, current_end_time_str), extra = list(markup = TRUE))
current_time <- current_time + chng_delta
i <- i + 1
} else {
tryCatch({
print(pytrend)
print(topic)
print(geo)
print(sprintf('%s %s', current_time_str, current_end_time_str))
pytrend$build_payload(kw_list = list(topic), geo = geo, timeframe = sprintf('%s %s', current_time_str, current_end_time_str))
#pytrend$build_payload(kw_list = list("/m/012gx2"), geo = geo, timeframe= sprintf('%s %s', current_time_str, current_end_time_str))
print(pytrend)
Sys.sleep(5)
df <- pytrend$interest_by_region(resolution = resolution, inc_geo_code = TRUE, inc_low_vol = TRUE)
print(pytrend)
#df$rename(dict(topic = keyword), inplace = TRUE)
df <- reticulate::py_to_r(df)
print(head(df))
names(df)[names(df) == keyword] <- keyword
i <- i + 1
#utils::write.csv(df, file_path, row.names = FALSE)
write.csv(df, file = file.path(folder_name, data_format, "by_region", paste0(form, "_", i, "-", format(current_time, "%Y%m%d"), "-", format(current_end_time, "%Y%m%d"), ".csv")))
}, error = function(e) {
if (inherits(e, "ResponseError")) {
logger$info("Please have patience as we reset rate limit ... ", extra = list(markup = TRUE))
Sys.sleep(5)
} else {
stop(e)
}
})
Sys.sleep(5)
current_time <- current_time + chng_delta
}
}
logger$info("[bold green]Successfully Collected Cross Section Data![/]", extra = list(markup = TRUE))
}
# Time Series Data collection method for 'monthly'
time_series_monthly <- function(params, reference_geo_code = "US") {
logger <- params$logger
pytrend <- params$pytrend
folder_name <- params$folder_name
data_format <- params$data_format
start_date <- params$start_date
end_date <- params$end_date
keyword <- params$keyword
topic <- params$topic
# Create file path
file_path <- file.path(folder_name, data_format, "over_time", reference_geo_code, sprintf("%s-%s.csv", format(start_date, "%Y%m%d"), format(end_date, "%Y%m%d")))
# Check if file already exists
if (file.exists(file_path)) {
logger$info("All Data for current request is already collected", extra = list(markup = TRUE))
} else {
tryCatch({
# Build the payload
pytrend$build_payload(kw_list = list(topic), geo = reference_geo_code,
timeframe = sprintf('%s %s', format(start_date, "%Y-%m-%d"), format(end_date, "%Y-%m-%d")))
Sys.sleep(5)
# Get interest over time data
df <- pytrend$interest_over_time()
# Convert to R dataframe and rename columns
df <- reticulate::py_to_r(df)
#colnames(df_r)[colnames(df_r) == topic] <- keyword
# Save the dataframe to a CSV file
write.csv(df, file_path)
}, ResponseError = function(e) {
logger$info("Please have patience as we reset rate limit ... ", extra = list(markup = TRUE))
Sys.sleep(5)
}, error = function(e) {
logger$error(sprintf("[bold red]Whoops![/] An error occurred during the request for period %d: %s", period, e$message), exc_info = TRUE, extra = list(markup = TRUE))
})
}
}
# Time Series Data collection method for 'weekly'/'daily'
time_series_nmonthly <- function(params, reference_geo_code = "US") {
logger <- params$logger
pytrend <- params$pytrend
folder_name <- params$folder_name
data_format <- params$data_format
times <- params$times
keyword <- params$keyword
topic <- params$topic
for (period in 1:(length(times) - 1)) {
start <- times[[period]]
end <- times[[period + 1]]
#print(start, "\n")
#print(end, "\n")
if (data_format == "weekly") {
num_days <- as.integer(difftime(end, start, units = "days"))
if (num_days < 270) {
#stats$stop()
stop(sprintf("For period: %d, days given: %d. Please increase timeline", period, num_days))
}
}
file_path <- file.path(folder_name, data_format, "over_time", reference_geo_code,
sprintf("%d-%s-%s.csv", period, format(start, "%Y%m%d"), format(end, "%Y%m%d")))
if (file.exists(file_path)) {
logger$info(sprintf("Data for %s to %s already collected. Moving to next date...", format(start, "%d/%m/%Y"), format(end, "%d/%m/%Y")), extra = list(markup = TRUE))
} else {
tryCatch({
print(pytrend, "\n")
#print(sprintf('%s %s', format(start, "%Y-%m-%d"), format(end, "%Y-%m-%d")))
pytrend$build_payload(kw_list = list(topic), geo = reference_geo_code,
timeframe = sprintf('%s %s', format(start, "%Y-%m-%d"), format(end, "%Y-%m-%d")))
Sys.sleep(5)
print(pytrend, "\n")
df <- pytrend$interest_over_time()
df <- reticulate::py_to_r(df)
if (nrow(df) == 0) {
logger$info(sprintf("No Data was returned for period: %d -> '%s' to '%s'", period, format(start, "%d/%m/%Y"), format(end, "%d/%m/%Y")))
} else {
#print("df has non 0 rows")
names(df)[names(df) == topic] <- keyword
if ("isPartial" %in% names(df)) {
df <- df[, !names(df) %in% "isPartial", drop = FALSE]
}
print(head(df))
write.csv(df, file_path)
}
}, ResponseError = function(e) {
logger$info("Please have patience as we reset rate limit ... ", extra = list(markup = TRUE))
Sys.sleep(5)
}, error = function(e) {
#stats$stop()
logger$error(sprintf("[bold red]Whoops![/] An error occurred during the request for period %d: %s", period, e$message), exc_info = TRUE, extra = list(markup = TRUE))
})
}
}
}
time_series <- function(params, reference_geo_code = "US") {
logger <- params$logger
folder_name <- params$folder_name
data_format <- params$data_format
time_window <- params$time_window
#print(params)
print(params$time_window)
logger$info("Collecting Over Time Data now")
create_required_directory(file.path(folder_name, data_format, "over_time"))
create_required_directory(file.path(folder_name, data_format, "over_time", reference_geo_code))
if (!is.null(time_window)) {
time_series_nmonthly(params, reference_geo_code)
} else {
print("minthly")
time_series_monthly(params, reference_geo_code)
}
logger$info("[bold green]Collected Time Series Data![/]")
}
concat_time_series <- function(params, reference_geo_code = "US", zero_replace = 0.1) {
logger <- params$logger
folder_name <- params$folder_name
data_format <- params$data_format
keyword <- params$keyword
print(keyword)
logger$info("Concatenating Over Time data now", extra = list(markup = TRUE))
# Create Folder to save the concatenated time series data
create_required_directory(file.path(folder_name, data_format, "concat_time_series"))
path_to_time_data <- file.path(folder_name, data_format, "over_time", reference_geo_code)
# List to store DataFrames
dfs <- list()
# Read each CSV file into a DataFrame and store in dfs list
files <- list.files(path_to_time_data, full.names = TRUE)
for (file in files) {
df <- read.csv(file, check.names = FALSE)
dfs[[length(dfs) + 1]] <- df
}
df <- df[, colSums(is.na(df)) != nrow(df)]
# Replace zeros with zero_replace value
for (i in seq_along(dfs)) {
dfs[[i]][dfs[[i]][[keyword]] == 0, keyword] <- zero_replace
}
# Concatenate the time series data
prev_window <- dfs[[1]]
#print(prev_window)
for (periods in 2:length(dfs)) {
#print(periods)
next_window <- dfs[[periods]]
prev_window_multiplier <- 100 / prev_window[nrow(prev_window), keyword]
next_window_multiplier <- 100 / next_window[1, keyword]
prev_window[, keyword] <- prev_window[, keyword] * prev_window_multiplier
next_window[, keyword] <- next_window[, keyword] * next_window_multiplier
prev_window <- rbind(prev_window[-nrow(prev_window), ], next_window)
#print(prev_window[, keyword])
}
# Write concatenated DataFrame to CSV
concat_file_path <- file.path(folder_name, data_format, "concat_time_series", paste0(reference_geo_code, ".csv"))
write.csv(prev_window, concat_file_path, row.names = FALSE)
logger$info("[bold green]Concatenation Complete! :)[/]", extra = list(markup = TRUE))
}
convert_cross_section <- function(params, reference_geo_code = "US", zero_replace = 0.1) {
logger <- params$logger
folder_name <- params$folder_name
data_format <- params$data_format
keyword <- params$keyword
start_date <- params$start_date
end_date <- params$end_date
logger$info("Rescaling cross section Data now", extra = list(markup = TRUE))
# Create required directories
create_required_directory(file.path(folder_name, data_format, "converted"))
create_required_directory(file.path(folder_name, data_format, "converted", reference_geo_code))
concat_file_path <- file.path(folder_name, data_format, "concat_time_series", paste0(reference_geo_code, ".csv"))
if (file.exists(concat_file_path)) {
time_series_concat <- read.csv(concat_file_path, header = TRUE, check.names = FALSE)
} else {
files_in_over_time <- list.files(file.path(folder_name, data_format, "over_time", reference_geo_code), full.names = TRUE)
time_series_concat <- read.csv(files_in_over_time, header = TRUE, check.names = FALSE)
#print(as.numeric(time_series_concat[[keyword]][10]))
}
names(time_series_concat)[names(time_series_concat) == ''] <- 'date'
print(colnames(time_series_concat))
# Initialize empty data frame for conversion result
conv <- data.frame()
# Iterate over rows in time_series_concat
for (ind in seq_len(nrow(time_series_concat))) {
record <- format(as.POSIXct(as.character(time_series_concat$date[ind]), format = "%Y-%m-%d %H:%M:%S"), "%Y%m%d")
time_ind <- as.numeric(time_series_concat[[keyword]][ind])
#cat(record, "\n")
#cat(time_ind, "\n")
# Construct snapshot file path based on record date
snap_file <- list.files(path = file.path(folder_name, data_format, "by_region"), pattern = paste0(".*", record, ".*csv"), full.names = TRUE)[1]
#print(snap_file)
# Extract column name from snapshot file
if (Sys.info()['sysname'] == "win32") {
fl_name <- tail(unlist(strsplit(snap_file, "\\\\")), 1)
} else {
fl_name <- tail(unlist(strsplit(snap_file, "/")), 1)
#print(fl_name)
}
col_name <- gsub("\\.csv", "", fl_name)
#cat(col_name)
# Read snapshot data
snap_df <- read.csv(snap_file, header = TRUE, stringsAsFactors = FALSE, na.strings = "", check.names = FALSE)
#print(head(snap_df))
snap_df[[keyword]][is.na(snap_df[[keyword]])] <- zero_replace
# Find reference value based on geoCode
ref_value <- as.numeric(snap_df[snap_df$geoCode == reference_geo_code, keyword])
#print(ref_value)
# Calculate conversion multiplier
conv_multiplier <- time_ind / ref_value
#print(conv_multiplier)
# Perform conversion on snapshot dataframe
snap_df[[col_name]] <- round(snap_df[[keyword]] * conv_multiplier, 2)
print(snap_df[[col_name]])
#print(conv)
# Collect initial geoName and geoCode if it's the first iteration
if (ind == 1) {
conv <- snap_df[c("geoName", "geoCode")]
#print(ref_value)
#print(conv_multiplier)
}
# Append converted data to conv data frame
#conv[[col_name]] <- snap_df[[keyword]]
conv[[col_name]] <- snap_df[[col_name]]
#print(snap_df[[keyword]])
}
# Write converted DataFrame to CSV
write.csv(conv, file.path(folder_name, data_format, "converted", reference_geo_code, paste0("final-converted-",
format(start_date, "%Y%m%d"), "-",
format(end_date, "%Y%m%d"), ".csv")), row.names = FALSE)
logger$info("[bold green]DONE Converting! :) [/]", extra = list(markup = TRUE))
}
# Example usage
params <- initialize_request_trends(
keyword = "Joe Biden",
topic = "/m/012gx2",
folder_name = "bidennn",
start_date = "2019-12-29",  # Date string
end_date = "2024-05-19",     # Date string
data_format = "weekly"
)
cross_section(params, geo = "US", resolution="REGION")
getwd()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
pak::pkg_install("rhub")
pkg_install("rhub")
install.packages("rhub")
library(rhub)
rhub::rhub_platforms()
getwd()
rhub::rhub_setup()
rhub::rhub_doctor()
rhub::rhub_check()
devtools::document()
devtools::build()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::build()
rhub::rhub_doctor()
rhub::rhub_platforms()
rhub::rhub_check()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
rhub::rhub_doctor()
rhub::rhub_platforms()
rhub::rhub_check()
getwd()
devtools::document()
devtools::build()
rhub::rhub_doctor()
rhub::rhub_check()
devtools::document()
devtools::build()
rhub::rhub_doctor()
rhub::rhub_check()
reticulate::py_discover_config()
?py_module_available
devtools::document()
devtools::document()
devtools::build()
rhub::rhub_doctor()
rhub::rhub_check()
devtools::document()
devtools::document()
devtools::build()
devtools::document()
library(reticulate)
devtools::document()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
Sys.which("python")
reticulate::py_config()
Sys.getenv()
py_discover_config()
devtools::document()
devtools::build()
py_discover_config()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
py_discover_config()
py_discover_config()
devtools::document()
py_discover_config()
Sys.which("python")
devtools::build()
rhub::rhub_check()
which(python)
python --v
devtools::document()
devtools::build()
rhub::rhub_check()
rhub::rhub_setup()
rhub::rhub_check()
reticulate::virtualenv_starter()
reticulate::virtualenv_create(envname = "~/.virtualenvs/pytrends-in-r", python = "/Users/malika/miniconda3/bin/python3.11")
devtools::document()
devtools::build()
py_discover_config()
reticulate::py_discover_config()
devtools::document()
devtools::document()
py_discover_config()
devtools::document()
devtools::document()
reticulate::py_last_error()
devtools::document()
reticulate::py_last_error()
if (!reticulate::py_module_available("pandas")) {
reticulate::py_install("pandas", envname = "pytrends-in-r-new", pip = TRUE)
}
devtools::document()
devtools::document()
reticulate::py_last_error()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
rhub::rhub_check()
devtools::document()
devtools::build()
rhub::rhub_check()
reticulate::virtualenv_starter(all = TRUE)
reticulate::virtualenv_starter(version = "3.11", all = TRUE)
reticulate:::can_be_virtualenv_starter("/usr/bin/python3.11")
reticulate:::can_be_virtualenv_starter("/Users/malika/miniconda3/bin/python3.11")
reticulate:::can_be_virtualenv_starter("C:/hostedtoolcache/windows/Python/3.9.13/x64/python.exe")
py_has_modules("/Users/malika/miniconda3/bin/python3.11", c("pip, "venv"))
py_has_modules("/usr/bin/python3.11", c("pip, "venv"))
reticulate:::can_be_virtualenv_starter("/Users/malika/miniconda3/bin/python3.11")
reticulate::install_python(version = '3.12')
reticulate::virtualenv_starter(all = TRUE)
debug(reticulate:::can_be_virtualenv_starter)
devtools::document()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
rhub::rhub_check()
devtools::document()
devtools::build()
rhub::rhub_check()
pyenv install --list
devtools::document()
devtools::build()
rhub::rhub_check()
Sys.getenv("PYTHON", "python")
Sys.getenv("GITHUB_ACTIONS", NA)
rhub::rhub_check()
devtools::document()
devtools::document()
devtools::build()
devtools::document()
devtools::build()
rhub::rhub_check()
Sys.getenv("PYTHON_PATH")
devtools::document()
devtools::build()
rhub::rhub_check()
devtools::document()
devtools::build()
rhub::rhub_check()
Sys.getenv("HOME")
reticulate::py_discover_config()
devtools::document()
devtools::document()
reticulate::py_discover_config()
class(reticulate::py_discover_config())
type(reticulate::py_discover_config())
class(reticulate::py_discover_config())[0]
class(reticulate::py_discover_config())[1]
class(reticulate::py_discover_config())[1]
reticulate::py_discover_config()[0]
reticulate::py_discover_config()[1]
reticulate::py_discover_config()[2]
devtools::document()
devtools::build()
devtools::document()
devtools::build()
rhub::rhub_check()
file.path(Sys.getenv("HOME"), ".virtualenvs", "pytrends-in-r-new")
file.path(venv_path, "bin", "python")
file.path("/Users/malika/.virtualenvs/pytrends-in-r-new", "bin", "python")
devtools::document()
devtools::build()
rhub::rhub_check()
devtools::document()
devtools::build()
rhub::rhub_check()
devtools::document()
devtools::document()
install_python(version = '3.11.9')
virtualenv_starter(desired_python_version)
virtualenv_starter("3.11.4")
reticulate::virtualenv_starter("3.11.4")
reticulate::virtualenv_starter("3.11.9")
reticulate::use_python_version("3.11.9")
reticulate::use_python_version("3.11.4")
devtools::document()
devtools::build()
rhub::rhub_check()
virtualenv_starter("3.11.4")
reticulate::virtualenv_starter("3.11.4")
devtools::document()
devtools::build()
rhub::rhub_check()
devtools::document()
devtools::build()
rhub::rhub_check()
devtools::build()
